<!DOCTYPE html>
<html>
	<head>
	<meta name="generator" content="Hugo 0.57.2" />
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>Weijie Su&nbsp;- USTC</title><link rel="apple-touch-icon" sizes="180x180" href="apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="favicon-16x16.png">
	<link rel="manifest" href="site.webmanifest">
	<link rel="mask-icon" href="safari-pinned-tab.svg" color="#5bbad5">
	<meta name="msapplication-TileColor" content="#da532c">
	<meta name="theme-color" content="#ffffff">

	<meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="alternate" type="application/rss+xml" href="https://jackroos.github.io/index.xml" title="Weijie Su" />
	<meta property="og:title" content="Weijie Su" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://jackroos.github.io/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Weijie Su"/>
<meta name="twitter:description" content=""/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:500,100,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="css/main.css" /><script src="js/feather.min.js"></script><script src="js/main.js"></script>
</head>


	<body>
		<div class="container wrapper">
			<div class="header">
	<img src=https://jackroos.github.io/xxw2024blue.jpg class="profile_image">
	<h1 class="site-title">Weijie Su</h1>
	<h2>(苏伟杰)</h2>
	<div class="site-affilation">
		<span class="affilation"><ul class="flat">
				<li class="position">Researcher, Shanghai AI Laboratory</li>
				<li class="email">suweijie@pjlab.org.cn</li>
			</ul></span>
		

		<nav class="nav social">
			<ul class="flat"><a href="https://github.com/jackroos" title="GitHub"><i data-feather="github"></i></a><a href="https://twitter.com/jackroos237" title="Twitter"><i data-feather="twitter"></i></a><a href="https://www.linkedin.com/in/weijie-su-abb163177/" title="LinkedIn"><i data-feather="linkedin"></i></a>
				|&nbsp;<a href="https://scholar.google.com/citations?user=ECDe6IIAAAAJ&amp;hl=en" class='blog_cv'>[Google Scholar]</a>
				
			</ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
		</ul>
	</nav>
</div>

			
			<div class="introduction">
	<h4><b>Short Bio</b></h4><span>
		Weijie Su is a final-year PhD student at University of Science and Technology of China (USTC), under the supervision of Prof. <a href="http://staff.ustc.edu.cn/~binli/">Bin Li</a> and Prof. <a href="https://jifengdai.org/">Jifeng Dai</a>. Before that, he received his Bachelor&rsquo;s degree from USTC in June 2019, majoring in Information and Computing Science (Computational Mathematics). Currently, he also works closely with Dr. <a href="https://scholar.google.com/citations?user=02RXI00AAAAJ">Xizhou Zhu</a>.
	</span>
	<br><span>
		<b>Research Interests&nbsp;</b> Multimodal Foundation Model; Pre-training / Representation Learning; Visual Recognition; General Capable Agents.
	</span>
</div>

                        <div class="introduction">
	<span>
		<p><b>If you are interested in an internship at Shanghai AI Laboratory related to my research field, please send me an email.</b></p>
	</span>
</div>
			
			<div class="introduction">
	<h4><b><i>News</i></b></h4><span>
		<strong><em>2023.05 &nbsp; &nbsp; Introducing <a href="https://github.com/OpenGVLab/GITM">GITM</a>, a Generally Capable Agent that Fully Masters Minecraft. </em></strong>
	</span><span>
		<em>2023.02 &nbsp; &nbsp; Our M3I Pre-training and SiameseIM are accepted by CVPR 2023. </em>
	</span><span>
		<em>2021.06 &nbsp; &nbsp; Presentation slides and video of our Deformable DETR on ICLR 2021 are available now. </em>
	</span><span>
		<em>2021.01 &nbsp; &nbsp; Deformable DETR is accepted for oral presentation by ICLR 2021</a>.</em>
	</span><span>
	</span><span>
		<em>2020.11 &nbsp; &nbsp; Code of Deformable DETR is now available at <a href="https://github.com/fundamentalvision/Deformable-DETR">this github repository</a>.</em>
	</span><span>
		<em>2020.05 &nbsp; &nbsp; Presentation slides and video of our VL-BERT on ICLR 2020 are available now.</em>
	</span><span>
		<em>2019.12 &nbsp; &nbsp; Our paper <a href="https://arxiv.org/abs/1908.08530">VL-BERT</a> got accepted by ICLR 2020.</em>
	</span><span>
		<em>2019.11 &nbsp; &nbsp; Code for our paper <a href="https://arxiv.org/abs/1908.08530">VL-BERT</a> has been made public available at <a href="https://github.com/jackroos/VL-BERT">github</a>.</em>
	</span></div>

			

			<div class="introduction">
	<h4><b>Experiences</b></h4><ul>
		<li>
			<em>2024.7 - Present</em>&nbsp; &nbsp;Researcher, Shanghai AI Laboratory.
		</li>
	</ul><ul>
		<li>
			<em>2024.1 - 2024.6</em>&nbsp; &nbsp;Research Intern, Shanghai AI Laboratory (Mentor: Prof. <a href="https://jifengdai.org/">Jifeng Dai</a>).
		</li>
	</ul><ul>
		<li>
			<em>2020.1 - 2024.6</em>&nbsp; &nbsp;Research Intern, SenseTime Research (Mentor: Prof. <a href="https://jifengdai.org/">Jifeng Dai</a> and Dr. <a href="https://scholar.google.com/citations?user=02RXI00AAAAJ">Xizhou Zhu</a>).
		</li>
	</ul><ul>
		<li>
			<em>2018.7 - 2019.9</em>&nbsp; &nbsp; Research Intern, Microsoft Research Asia (Mentor: Prof. <a href="https://jifengdai.org/">Jifeng Dai</a>).
		</li>
	</ul><ul>
		<li>
			<em>2017.7 - 2018.6</em>&nbsp; &nbsp; Research Intern, <a href="http://gcl.ustc.edu.cn/">GCL Lab</a> at USTC (Mentor: Prof. <a href="http://staff.ustc.edu.cn/~lgliu/">Ligang Liu</a>).
		</li>
	</ul></div>
			<div class="introduction">
	<h4><b>Honors</b></h4><ul>
		<li>
			Outstanding Graduate, University of Science and Technology of China, 2024.
		</li>
	</ul><ul>
	        <li>
			Future Star Award (未来之星奖), SenseTime, 2024.
		</li>
	</ul><ul>
		<li>
			National Scholarship (国家奖学金), Ministry of Education of the People's Republic of China, 2020.
		</li>
	</ul><ul>
		<li>
			Outstanding Graduate, University of Science and Technology of China, 2019.
		</li>
	</ul><ul>
		<li>
			Bronze Medal, The 30th Chinese Mathematical Olympiad (CMO), 2014。
		</li>
	</ul></div>
			<div class="introduction">
	
</div>

			<div class="introduction">
	
	<h4><b>Publications</b></h4>
    <h6>(<sup>†</sup> Equal Contribution)</h6><div class="year"></div>

	<ul>
		<li>
			<a href="https://arxiv.org/abs/2406.07543" class="publications"> Vision Model Pre-training on Interleaved Image-Text Data via Latent Compression Learning</a>
			
			<span class="code_blog">
				
				[<a href="https://github.com/OpenGVLab/LCL">Code</a>]

				[<a href="https://zhuanlan.zhihu.com/p/703084363?utm_psn=1791107702786764800">Blog</a>]
				
			</span>
			
			<span class="collaborators">
				Chenyu Yang<sup>†</sup>, Xizhou Zhu<sup>†</sup>, Jinguo Zhu<sup>†</sup>, <strong>Weijie Su</strong>, Junjie Wang, Xuan Dong, Wenhai Wang, Lewei Lu, Bin Li, Jie Zhou, Yu Qiao, Jifeng Dai
			</span>
			
			<span class="collaborators">
				Arxiv Preprint, 2024.
			</span>
			
		</li>
		
                <li>
			<a href="https://arxiv.org/abs/2312.14238" class="publications"> InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks</a>
			
			<span class="code_blog">
				
				[<a href="https://github.com/OpenGVLab/InternVL">Code</a>]
				
				[<a href="https://mp.weixin.qq.com/s/bdfAJRqOF9tUk8Vy9KC_XQ">Blog</a>]
																
			</span>
			
			<span class="collaborators">
				Zhe Chen, Jiannan Wu, Wenhai Wang, <strong>Weijie Su</strong>, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, Bin Li, Ping Luo, Tong Lu, Yu Qiao, Jifeng Dai
			</span>
			
			<span class="collaborators">
				IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2024.  
			</span>
			
		</li>
		
		<li>
			<a href="https://arxiv.org/abs/2305.17144" class="publications"> Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory</a>
			
			<span class="code_blog">
				
				[<a href="https://github.com/OpenGVLab/GITM">Project Page</a>]
								
				[<a href="https://medium.com/p/994590ed6760">Blog</a>]
				
				[<a href="https://youtube.com/playlist?list=PL6lJnoxTvWMYKa16ETZtNWaZW5233Noue">Demo</a>]
				
			</span>
			
			<span class="collaborators">
				Xizhou Zhu<sup>†</sup>, Yuntao Chen<sup>†</sup>, Hao Tian<sup>†</sup>, Chenxin Tao<sup>†</sup>, <strong>Weijie Su</strong><sup>†</sup>, Chenyu Yang<sup>†</sup>, Gao Huang, Bin Li, Lewei Lu, Xiaogang Wang, Yu Qiao, Zhaoxiang Zhang, Jifeng Dai
			</span>
			
			<span class="collaborators">
				Arxiv Preprint, 2023. 
			</span>
			
		</li>
		
		<li>
			
			<a href="https://arxiv.org/abs/2211.09807" class="publications"> Towards All-in-one Pre-training via Maximizing Multi-modal Mutual Information</a>
			
			<span class="code_blog">
				
				[<a href="https://github.com/OpenGVLab/M3I-Pretraining">Code</a>]
				
				[<a href="https://www.weijiesu.com/research/M3I-Pretraining/M3I_CVPR_present_without_recording.pdf">Slides</a>]
				
				[<a href="https://www.youtube.com/watch?v=3O_SPwAJ86Y">Presentation</a>]
				
			</span>
			
			<span class="collaborators">
				<strong>Weijie Su</strong><sup>†</sup>, Xizhou Zhu<sup>†</sup>, Chenxin Tao<sup>†</sup>, Lewei Lu, Bin Li, Gao Huang, Yu Qiao, Xiaogang Wang, Jie Zhou, Jifeng Dai
			</span>
			
			<span class="collaborators">
				IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023. 
			</span>
			
		</li>
		
		<li>
			
			<a href="https://arxiv.org/abs/2206.01204" class="publications"> Siamese Image Modeling for Self-Supervised Vision Representation Learning</a>
			
			<span class="collaborators">
				Chenxin Tao<sup>†</sup>, Xizhou Zhu<sup>†</sup>, <strong>Weijie Su</strong><sup>†</sup>, Gao Huang, Bin Li, Jie Zhou, Yu Qiao, Xiaogang Wang, Jifeng Dai
			</span>
			
			<span class="collaborators">
				IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2023.
			</span>
			
		</li>
		
		<li>
			
			<a href="https://arxiv.org/abs/2010.04159" class="publications"> Deformable DETR: Deformable Transformers for End-to-End Object Detection</a>
			

			
			<span class="code_blog">
				
				[<a href="https://github.com/fundamentalvision/Deformable-DETR">Code</a>]
				
				[<a href="https://www.jiqizhixin.com/articles/2020-10-13-6">Blog</a>]
				
				[<a href="https://www.weijiesu.com/research/Deformable-DETR/deformable_detr_iclr_presentation.pdf">Slides</a>]

				[<a href="https://slideslive.com/38953665/deformable-detr-deformable-transformers-for-endtoend-object-detection?ref=speaker-29434-latest">Presentation</a>]
				
			</span>
			

			<span class="collaborators">
				Xizhou Zhu<sup>†</sup>, <strong>Weijie Su</strong><sup>†</sup>, Lewei Lu, Bin Li, Xiaogang Wang, Jifeng Dai
			</span>
			
			<span class="collaborators">
				International Conference on Learning Representations (ICLR), 2021. (<strong>Oral</strong>)
			</span>
			
		</li>
		
		<li>
			
			<a href="https://arxiv.org/abs/1908.08530" class="publications"> VL-BERT: Pre-training of Generic Visual-Linguistic Representations</a>
			

			
			<span class="code_blog">
				
				[<a href="https://github.com/jackroos/VL-BERT">Code</a>]
				

				

				
				[<a href="https://www.weijiesu.com/research/VL-BERT/VL-BERT-ICLR-present-final.pdf">Slides</a>]
				

				
				[<a href="https://iclr.cc/virtual_2020/poster_SygXPaEYvH.html">Presentation</a>]
				
			</span>
			

			<span class="collaborators">
				<strong>Weijie Su</strong><sup>†</sup>, Xizhou Zhu<sup>†</sup>, Yue Cao, Bin Li, Lewei Lu, Furu Wei, Jifeng Dai
			</span>
			
			<span class="collaborators">
				International Conference on Learning Representations (ICLR), 2020.
			</span>
			
		</li>
		
	</ul></div>

		</div>
		</div>

		


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-146428647-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<script>
	feather.replace()

</script>
		
	</body>

</html>
